{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61611edc",
   "metadata": {},
   "source": [
    "## Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d5e3a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÇ Reading from: /workspaces/MAP_Hackathon_2026_G4/src/data/raw_full\n",
      "üéØ Saving to: /workspaces/MAP_Hackathon_2026_G4/src/data/processed\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Config\n",
    "RAW_DIR = os.path.join(os.getcwd(), \"data\", \"raw_full\")\n",
    "PROCESSED_DIR = os.path.join(os.getcwd(), \"data\", \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# Threshold: Drop columns with > 50% missing values\n",
    "MISSING_THRESHOLD = 0.5 \n",
    "\n",
    "print(f\"üìÇ Reading from: {RAW_DIR}\")\n",
    "print(f\"üéØ Saving to: {PROCESSED_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3775b749",
   "metadata": {},
   "source": [
    "## Load All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d458f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Found 131 files.\n",
      "‚öì Anchor File: DEMO_J.xpt\n",
      "   Initial Shape: (9254, 46)\n",
      "   Memory Usage: 3.25 MB\n"
     ]
    }
   ],
   "source": [
    "# 1. Get all file paths\n",
    "all_files = glob.glob(os.path.join(RAW_DIR, \"*.xpt\")) + glob.glob(os.path.join(RAW_DIR, \"*.XPT\"))\n",
    "print(f\"üîç Found {len(all_files)} files.\")\n",
    "\n",
    "# 2. Find DEMO file (Anchor dataset)\n",
    "demo_path = next((f for f in all_files if \"DEMO\" in os.path.basename(f).upper()), None)\n",
    "if not demo_path:\n",
    "    raise FileNotFoundError(\"CRITICAL: DEMO file not found! Cannot start merging.\")\n",
    "\n",
    "print(f\"‚öì Anchor File: {os.path.basename(demo_path)}\")\n",
    "df_master = pd.read_sas(demo_path)\n",
    "df_master['SEQN'] = df_master['SEQN'].astype(int)\n",
    "base_seqns = set(df_master['SEQN'])  # For rapid screen\n",
    "\n",
    "print(f\"   Initial Shape: {df_master.shape}\")\n",
    "print(f\"   Memory Usage: {df_master.memory_usage().sum() / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1734b5",
   "metadata": {},
   "source": [
    "## Memory-Optimized Iterative Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d76cc681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting iterative merge...\n",
      "   ... Merged 10 files. Master Shape: (17529, 758)\n",
      "‚ö†Ô∏è Error processing FASTQX_J.xpt: name 'gc' is not defined\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "dropped_vars_count = 0\n",
    "\n",
    "print(\"üöÄ Starting iterative merge...\")\n",
    "\n",
    "for f in all_files:\n",
    "    if f == demo_path: continue\n",
    "    \n",
    "    try:\n",
    "        # A. Read file\n",
    "        df_temp = pd.read_sas(f)\n",
    "        \n",
    "        # B. Check for SEQN (Primary Key)\n",
    "        if 'SEQN' not in df_temp.columns:\n",
    "            continue\n",
    "        \n",
    "        df_temp['SEQN'] = df_temp['SEQN'].astype(int)\n",
    "        \n",
    "        # C. [Optimization] Row Filtering\n",
    "        # Only keep rows that exist in the base DEMO dataset.\n",
    "        # This removes data for participants not in the main demographic group (e.g., children if excluded).\n",
    "        df_temp = df_temp[df_temp['SEQN'].isin(base_seqns)]\n",
    "        \n",
    "        if df_temp.empty:\n",
    "            continue\n",
    "\n",
    "        # D. [Optimization] Pre-merge Column Filtering\n",
    "        # Calculate missing rate BEFORE merging. If a column is mostly empty, don't bring it in.\n",
    "        cols_to_keep = ['SEQN']\n",
    "        for col in df_temp.columns:\n",
    "            if col == 'SEQN': continue\n",
    "            \n",
    "            # Calculate missing percentage for this column\n",
    "            missing_rate = df_temp[col].isnull().mean()\n",
    "            \n",
    "            if missing_rate <= MISSING_THRESHOLD:\n",
    "                cols_to_keep.append(col)\n",
    "            else:\n",
    "                dropped_vars_count += 1\n",
    "        \n",
    "        # Keep only the useful columns\n",
    "        df_temp = df_temp[cols_to_keep]\n",
    "        \n",
    "        # If no columns remain (other than SEQN), skip this file\n",
    "        if len(df_temp.columns) <= 1:\n",
    "            continue\n",
    "\n",
    "        # E. Merge into Master DataFrame\n",
    "        df_master = pd.merge(df_master, df_temp, on='SEQN', how='left')\n",
    "        \n",
    "        count += 1\n",
    "        \n",
    "        # F. [Optimization] Garbage Collection\n",
    "        # Explicitly delete the temporary dataframe and run garbage collection to free up RAM.\n",
    "        del df_temp\n",
    "        if count % 10 == 0:\n",
    "            print(f\"   ... Merged {count} files. Master Shape: {df_master.shape}\")\n",
    "            gc.collect()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing {os.path.basename(f)}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6f905f",
   "metadata": {},
   "source": [
    "## Final Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43df5dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"üéâ Merge Complete!\")\n",
    "print(f\"üìä Final Shape: {df_master.shape}\")\n",
    "print(f\"üóëÔ∏è Total Variables Dropped (Pre-filter): {dropped_vars_count}\")\n",
    "\n",
    "# Save as CSV\n",
    "csv_path = os.path.join(PROCESSED_DIR, \"nhanes_2017_2018_filtered.csv\")\n",
    "df_master.to_csv(csv_path, index=False)\n",
    "print(f\"üíæ Saved CSV to: {csv_path}\")\n",
    "\n",
    "# Save as Pickle (Recommended for Python workflows - reads/writes much faster)\n",
    "pkl_path = os.path.join(PROCESSED_DIR, \"nhanes_2017_2018_filtered.pkl\")\n",
    "df_master.to_pickle(pkl_path)\n",
    "print(f\"üíæ Saved Pickle to: {pkl_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af7a88",
   "metadata": {},
   "source": [
    "## Calculate Missing Rates (Memory Safe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbf9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import gc  # Garbage Collection\n",
    "\n",
    "# === Configuration ===\n",
    "# Path to your raw XPT files\n",
    "RAW_DIR = os.path.join(os.getcwd(), \"data\", \"raw_full\")\n",
    "MISSING_THRESHOLD = 0.5  # 50% threshold\n",
    "\n",
    "print(f\"üìÇ Scanning files in: {RAW_DIR}\")\n",
    "all_files = glob.glob(os.path.join(RAW_DIR, \"*.xpt\")) + glob.glob(os.path.join(RAW_DIR, \"*.XPT\"))\n",
    "print(f\"üîç Found {len(all_files)} files. Calculating missing rates iteratively...\")\n",
    "\n",
    "var_missing_rates = {}\n",
    "\n",
    "for i, f in enumerate(all_files):\n",
    "    try:\n",
    "        # Read one file at a time\n",
    "        df_temp = pd.read_sas(f)\n",
    "        \n",
    "        # Calculate missing rate for each variable in this file\n",
    "        # This returns a Series like: {'SEQN': 0.0, 'LBXGLU': 0.1, ...}\n",
    "        rates = df_temp.isnull().mean()\n",
    "        \n",
    "        # Store in our master dictionary\n",
    "        # Note: If a variable appears in multiple files (like SEQN), this will overwrite with the latest.\n",
    "        # Since variables are mostly unique to specific tables, this is fine for a general overview.\n",
    "        var_missing_rates.update(rates.to_dict())\n",
    "        \n",
    "        # Free memory immediately\n",
    "        del df_temp\n",
    "        gc.collect()\n",
    "        \n",
    "        # Progress indicator\n",
    "        if (i + 1) % 20 == 0:\n",
    "            print(f\"   Processed {i + 1}/{len(all_files)} files...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error reading {os.path.basename(f)}: {e}\")\n",
    "\n",
    "# Convert dictionary to Series for your plotting code\n",
    "missing_series = pd.Series(var_missing_rates)\n",
    "\n",
    "print(f\"\\n‚úÖ Analysis Complete!\")\n",
    "print(f\"   Total Variables Analyzed: {len(missing_series)}\")\n",
    "print(f\"   Variables to Keep (< {MISSING_THRESHOLD*100}% missing): {len(missing_series[missing_series <= MISSING_THRESHOLD])}\")\n",
    "print(f\"   Variables to Drop (> {MISSING_THRESHOLD*100}% missing): {len(missing_series[missing_series > MISSING_THRESHOLD])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e757be",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b97318",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what kept vs dropped\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(missing_series * 100, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.axvline(MISSING_THRESHOLD * 100, color='red', linestyle='--', label=f'Cutoff ({MISSING_THRESHOLD*100}%)')\n",
    "plt.title('Distribution of Missing Data % Across All Variables')\n",
    "plt.xlabel('% Missing')\n",
    "plt.ylabel('Number of Variables')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd00a05c",
   "metadata": {},
   "source": [
    "## Filter by Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef9df78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üßπ Starting Filtration...\")\n",
    "\n",
    "# 1. Calculate missing rates\n",
    "missing_series = df_master.isnull().mean()\n",
    "\n",
    "# 2. Identify keep vs drop\n",
    "keep_cols = missing_series[missing_series <= MISSING_THRESHOLD].index\n",
    "drop_cols = missing_series[missing_series > MISSING_THRESHOLD].index\n",
    "\n",
    "print(f\"   Total Variables: {len(missing_series)}\")\n",
    "print(f\"   Keep (<= {MISSING_THRESHOLD*100}% missing): {len(keep_cols)}\")\n",
    "print(f\"   Drop (> {MISSING_THRESHOLD*100}% missing): {len(drop_cols)}\")\n",
    "\n",
    "# 3. Create filtered DataFrame\n",
    "df_clean = df_master[keep_cols].copy()\n",
    "\n",
    "# 4. Save\n",
    "save_path = os.path.join(PROCESSED_DIR, \"nhanes_2017_2018_filtered.csv\")\n",
    "# Use pickle for faster IO in Python, or CSV for compatibility\n",
    "df_clean.to_csv(save_path, index=False)\n",
    "df_clean.to_pickle(os.path.join(PROCESSED_DIR, \"nhanes_2017_2018_filtered.pkl\"))\n",
    "\n",
    "print(f\"\\nüéâ Saved clean data to: {save_path}\")\n",
    "print(f\"üìä Final Clean Shape: {df_clean.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d91295",
   "metadata": {},
   "source": [
    "## Visualize Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38476618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what we kept vs dropped\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(missing_series * 100, bins=20, color='skyblue', edgecolor='black')\n",
    "plt.axvline(MISSING_THRESHOLD * 100, color='red', linestyle='--', label=f'Cutoff ({MISSING_THRESHOLD*100}%)')\n",
    "plt.title('Distribution of Missing Data % Across All Variables')\n",
    "plt.xlabel('% Missing')\n",
    "plt.ylabel('Number of Variables')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coi_hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
